# Robots.txt for Amarillo Automation
# Preventing search engine indexing during development phase
# Remove or modify when ready for SEO traffic

# Block all web crawlers from all content
User-agent: *
Disallow: /

# Specifically block major search engines
User-agent: Googlebot
Disallow: /

User-agent: Bingbot
Disallow: /

User-agent: Slurp
Disallow: /

User-agent: DuckDuckBot
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: facebookexternalhit
Disallow: /

User-agent: Twitterbot
Disallow: /

User-agent: LinkedInBot
Disallow: /

# Block SEO/analysis tools that consume bandwidth
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

# Allow specific beneficial crawlers (optional)
# User-agent: GTmetrix
# Allow: /

# No sitemap specified during no-index phase
# Sitemap: https://amarilloautomation.com/sitemap.xml